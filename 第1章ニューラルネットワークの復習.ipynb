{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "第1章ニューラルネットワークの復習.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMlCCDkmJn68E1DGCM69wI2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Repeatノード"
      ],
      "metadata": {
        "id": "r1_-RJAkLf4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "a8aZgKTULs-q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D, N = 8, 7\n",
        "x = np.random.randn(1, D)\n",
        "y = np.repeat(x, N, axis=0)\n",
        "\n",
        "dy = np.random.randn(N, D)\n",
        "dx = np.sum(dy, axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "lQYY_tTcLu79"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sumノード"
      ],
      "metadata": {
        "id": "v3Pxu1qyMG5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D, N = 8, 7\n",
        "x = np.random.randn(1, D)\n",
        "y = np.sum(x, axis=0, keepdims=True)\n",
        "\n",
        "dy = np.random.randn(1, D)\n",
        "dx = np.repeat(dy, N, axis=0)"
      ],
      "metadata": {
        "id": "IPMULMbzMUbW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MatMulノード"
      ],
      "metadata": {
        "id": "Sdy6n_YYMki2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MatMul:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.x = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        W, = self.params\n",
        "        out = np.dot(x, W)\n",
        "        self.x = x\n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        W, = self.params\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        self.grads[0][...] = dW\n",
        "        return dx"
      ],
      "metadata": {
        "id": "ukBtQtZyNBy3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoidレイヤ"
      ],
      "metadata": {
        "id": "FT9KwcqwNvVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = 1 / (1 + np.exp(-x))\n",
        "        self.out = out\n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "        return dx"
      ],
      "metadata": {
        "id": "OeDTaC0COVyy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Affineレイヤ"
      ],
      "metadata": {
        "id": "XXm6Q-bhOzya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        W, b = self.params\n",
        "        out = np.dot(x, W) + b\n",
        "        self.x = x\n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        W, b = self.params\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        db = np.sum(dout, axis=0)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "        return dx"
      ],
      "metadata": {
        "id": "TXsmLVH_PSsu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD(確率的勾配降下法)"
      ],
      "metadata": {
        "id": "vS1DmwNyP_uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        for i in range(len(params)):\n",
        "            params[i] -= self.lr * grads[i]"
      ],
      "metadata": {
        "id": "a5gPsbw1QgCo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データセット\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_data(seed=1984):\n",
        "    np.random.seed(seed)\n",
        "    N = 100  # クラスごとのサンプル数\n",
        "    DIM = 2  # データの要素数\n",
        "    CLS_NUM = 3  # クラス数\n",
        "\n",
        "    x = np.zeros((N*CLS_NUM, DIM))\n",
        "    t = np.zeros((N*CLS_NUM, CLS_NUM), dtype=np.int)\n",
        "\n",
        "    for j in range(CLS_NUM):\n",
        "        for i in range(N):#N*j, N*(j+1)):\n",
        "            rate = i / N\n",
        "            radius = 1.0*rate\n",
        "            theta = j*4.0 + 4.0*rate + np.random.randn()*0.2\n",
        "\n",
        "            ix = N*j + i\n",
        "            x[ix] = np.array([radius*np.sin(theta),\n",
        "                              radius*np.cos(theta)]).flatten()\n",
        "            t[ix, j] = 1\n",
        "\n",
        "    return x, t"
      ],
      "metadata": {
        "id": "oOQVnfsEQ0z6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x, t = load_data()\n",
        "print('x', x.shape)\n",
        "print('t', t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7tK5TdbRA9b",
        "outputId": "3f5dbe8c-a472-46d7-8604-04f905f535a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (300, 2)\n",
            "t (300, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ニューラルネットワークの実装"
      ],
      "metadata": {
        "id": "Np9zA9BESMeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "vys0pmJfRiNS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "wYJcX6uQZPSr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.y = None  # softmaxの出力\n",
        "        self.t = None  # 教師ラベル\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "\n",
        "        # 教師ラベルがone-hotベクトルの場合、正解のインデックスに変換\n",
        "        if self.t.size == self.y.size:\n",
        "            self.t = self.t.argmax(axis=1)\n",
        "\n",
        "        loss = cross_entropy_error(self.y, self.t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = self.y.copy()\n",
        "        dx[np.arange(batch_size), self.t] -= 1\n",
        "        dx *= dout\n",
        "        dx = dx / batch_size\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "bU6qVB9YSA5J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        I, H, O = input_size, hidden_size, output_size\n",
        "\n",
        "        # 重みとバイアスの初期化\n",
        "        W1 = 0.01 * np.random.randn(I, H)\n",
        "        b1 = np.zeros(H)\n",
        "        W2 = 0.01 * np.random.randn(H, O)\n",
        "        b2 = np.zeros(O)\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = [\n",
        "            Affine(W1, b1),\n",
        "            Sigmoid(),\n",
        "            Affine(W2, b2)\n",
        "        ]\n",
        "        self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "        # 全ての重みと勾配をリストにまとめる\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "    \n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x, t):\n",
        "        score = self.predict(x)\n",
        "        loss = self.loss_layer.forward(score, t)\n",
        "        return loss\n",
        "    \n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout"
      ],
      "metadata": {
        "id": "0f4jiY3ASFQi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習"
      ],
      "metadata": {
        "id": "9JLofWVvadY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの設定\n",
        "max_epoch = 300\n",
        "batch_size = 30\n",
        "hidden_size = 10\n",
        "learning_rate = 1.0\n",
        "\n",
        "# データ読み込み、モデルとオプティマイザの生成\n",
        "x, t = load_data()\n",
        "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
        "optimizer = SGD(lr=learning_rate)\n",
        "\n",
        "# 学習でしようする変数\n",
        "data_size = len(x)\n",
        "max_iters = data_size // batch_size\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    # データのシャッフル\n",
        "    idx = np.random.permutation(data_size)\n",
        "    x = x[idx]\n",
        "    t = t[idx]\n",
        "\n",
        "    for iters in range(max_iters):\n",
        "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "    \n",
        "    # 勾配を求め、パラメータを更新\n",
        "    loss = model.forward(batch_x, batch_t)\n",
        "    model.backward()\n",
        "    optimizer.update(model.params, model.grads)\n",
        "\n",
        "    total_loss += loss\n",
        "    loss_count += 1\n",
        "\n",
        "    # 定期的に学習経過を出力\n",
        "    if (iters+1) % 10 ==0:\n",
        "        avg_loss = total_loss / loss_count\n",
        "        print('| epoch %d | iter %d | loss %.2f' % (epoch + 1, iters + 1, max_iters, avg_loss))\n",
        "        loss_list.append(avg_loss)\n",
        "        total_loss, loss_count = 0, 0"
      ],
      "metadata": {
        "id": "yXkdJNnuav3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainerクラス"
      ],
      "metadata": {
        "id": "iGz-avkic1XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_grads(grads, max_norm):\n",
        "    total_norm = 0\n",
        "    for grad in grads:\n",
        "        total_norm += np.sum(grad ** 2)\n",
        "    total_norm = np.sqrt(total_norm)\n",
        "\n",
        "    rate = max_norm / (total_norm + 1e-6)\n",
        "    if rate < 1:\n",
        "        for grad in grads:\n",
        "            grad *= rate"
      ],
      "metadata": {
        "id": "dDBEJVgqdhpL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicate(params, grads):\n",
        "    '''\n",
        "    パラメータ配列中の重複する重みをひとつに集約し、\n",
        "    その重みに対応する勾配を加算する\n",
        "    '''\n",
        "    params, grads = params[:], grads[:]  # copy list\n",
        "\n",
        "    while True:\n",
        "        find_flg = False\n",
        "        L = len(params)\n",
        "\n",
        "        for i in range(0, L - 1):\n",
        "            for j in range(i + 1, L):\n",
        "                # 重みを共有する場合\n",
        "                if params[i] is params[j]:\n",
        "                    grads[i] += grads[j]  # 勾配の加算\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "                # 転置行列として重みを共有する場合（weight tying）\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
        "                    grads[i] += grads[j].T\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "\n",
        "                if find_flg: break\n",
        "            if find_flg: break\n",
        "\n",
        "        if not find_flg: break\n",
        "\n",
        "    return params, grads"
      ],
      "metadata": {
        "id": "UsdVLGyEd_sT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_list = []\n",
        "        self.eval_interval = None\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
        "        data_size = len(x)\n",
        "        max_iters = data_size // batch_size\n",
        "        self.eval_interval = eval_interval\n",
        "        model, optimizer = self.model, self.optimizer\n",
        "        total_loss = 0\n",
        "        loss_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            # シャッフル\n",
        "            idx = np.random.permutation(np.arange(data_size))\n",
        "            x = x[idx]\n",
        "            t = t[idx]\n",
        "\n",
        "            for iters in range(max_iters):\n",
        "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "                # 勾配を求め、パラメータを更新\n",
        "                loss = model.forward(batch_x, batch_t)\n",
        "                model.backward()\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
        "                if max_grad is not None:\n",
        "                    clip_grads(grads, max_grad)\n",
        "                optimizer.update(params, grads)\n",
        "                total_loss += loss\n",
        "                loss_count += 1\n",
        "\n",
        "                # 評価\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "                    avg_loss = total_loss / loss_count\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    print('| epoch %d |  iter %d / %d | time %d[s] | loss %.2f'\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
        "                    self.loss_list.append(float(avg_loss))\n",
        "                    total_loss, loss_count = 0, 0\n",
        "\n",
        "            self.current_epoch += 1\n",
        "\n",
        "    def plot(self, ylim=None):\n",
        "        x = np.arange(len(self.loss_list))\n",
        "        if ylim is not None:\n",
        "            plt.ylim(*ylim)\n",
        "        plt.plot(x, self.loss_list, label='train')\n",
        "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
        "        plt.ylabel('loss')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "s5uDBjpZeFsV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ビット精度"
      ],
      "metadata": {
        "id": "jKCJsScQeaCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.randn(3)\n",
        "a.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oejYr4dnee5a",
        "outputId": "a90a2990-0f39-499f-8c69-9308d609869c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.random.randn(3).astype(np.float32)\n",
        "b.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuUDGnuPekT2",
        "outputId": "cc3ffd1a-e988-4a6e-d153-a310ed272e66"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.random.randn(3).astype('f')\n",
        "c.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEEwGPlSerwZ",
        "outputId": "66ffa29a-fa01-473e-937c-dac577592ed7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU"
      ],
      "metadata": {
        "id": "OKvS0ungewC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy-cuda101\n",
        "!pip install chainer\n",
        "import cupy as cp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iddn8Uqse3Gl",
        "outputId": "15a81e07-95ba-43bd-f5f9-37973847cdf5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy-cuda101\n",
            "  Downloading cupy_cuda101-9.6.0-cp37-cp37m-manylinux1_x86_64.whl (60.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.2 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.17 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda101) (1.21.5)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda101) (0.8)\n",
            "Installing collected packages: cupy-cuda101\n",
            "Successfully installed cupy-cuda101-9.6.0\n",
            "Collecting chainer\n",
            "  Downloading chainer-7.8.1.tar.gz (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from chainer) (57.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from chainer) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from chainer) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (1.15.0)\n",
            "Building wheels for collected packages: chainer\n",
            "  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chainer: filename=chainer-7.8.1-py3-none-any.whl size=967740 sha256=65ee5ee4df9144c4e2e14f90f145d6ec5bfc6fce358a2b87bc9db23a5d780dca\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/6a/6f/fd563166cc597e5206e375ea074ea836e5db5dd58421215672\n",
            "Successfully built chainer\n",
            "Installing collected packages: chainer\n",
            "Successfully installed chainer-7.8.1\n"
          ]
        }
      ]
    }
  ]
}