{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "第5章リカレントニューラルネットワーク.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzFSFIokhD5cEppWm6lB5E"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zmrup3tRsTBi"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNレイヤの実装"
      ],
      "metadata": {
        "id": "XtSO7GS5wR0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "    \n",
        "    def forward(self, x, h_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
        "        h_next = np.tanh(t)\n",
        "\n",
        "        self.cache = (x, h_prev, h_next)\n",
        "        return h_next\n",
        "    \n",
        "    def backward(self, dh_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, h_next = self.cache\n",
        "\n",
        "        dt = dh_next * (1 - h_next ** 2)\n",
        "        db = np.sum(dt, axis=0)\n",
        "        dWh = np.dot(h_prev.T, dt)\n",
        "        dh_prev = np.dot(dt, Wh.T)\n",
        "        dWx = np.dot(x.T, dt)\n",
        "        dx = np.dot(dt, Wx.T)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        return dx, dh_prev"
      ],
      "metadata": {
        "id": "Jf6vcy_Lsd5d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time RNNレイヤの実装"
      ],
      "metadata": {
        "id": "tSkqE8rQtPXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeRNN:\n",
        "    def _init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_lile(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.dh = None, None\n",
        "        self.stateful = stateful\n",
        "    \n",
        "    def set_state(self, h):\n",
        "        self.h = h\n",
        "    \n",
        "    def reset_state(self):\n",
        "        self.h = None\n",
        "    \n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros_like((N, H), dtype='f')\n",
        "        \n",
        "        for t in range(T):\n",
        "            layer = RNN(*self.params)\n",
        "            self.h = layer.forward(xs[:, t, :], self.h)\n",
        "            hs[:, t, :] = self.h\n",
        "            self.layers.append(layer)\n",
        "        return hs\n",
        "    \n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        df = 0\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh = layer.backward(dhs[:, t, :] + dh) # 合算した勾配\n",
        "            dxs[:, t, :] = dx\n",
        "\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "        \n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "\n",
        "        return dxs"
      ],
      "metadata": {
        "id": "VpJ-tzxQwWm2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNLMの実装"
      ],
      "metadata": {
        "id": "n3iYdZTuw-lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time_layers"
      ],
      "metadata": {
        "id": "qt3li1sx6U8H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRnnlm:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        # 重みの初期化\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
        "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
        "        rnn_b = np.zeros(H).astype('f')\n",
        "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = [\n",
        "            time_layers.TimeEmbedding(embed_W),\n",
        "            time_layers.TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
        "            time_layers.TimeAffine(affine_W, affine_b)\n",
        "        ]\n",
        "        self.loss_layer = time_layers.TimeSoftmaxWithLoss()\n",
        "        self.rnn_layer = self.layers[1]\n",
        "\n",
        "        # 全ての重みと勾配をリストにまとめる\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "    \n",
        "    def forward(self, xs, ts):\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        loss = self.loss_layer.forward(xs, ts)\n",
        "        return loss\n",
        "    \n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "    \n",
        "    def reset_state(self):\n",
        "        self.rnn_layer.reset_state()"
      ],
      "metadata": {
        "id": "598x5gcR5Li5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNLMの学習コード"
      ],
      "metadata": {
        "id": "rzuKDtKq8Pgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    '''\n",
        "    確率的勾配降下法（Stochastic Gradient Descent）\n",
        "    '''\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        for i in range(len(params)):\n",
        "            params[i] -= self.lr * grads[i]"
      ],
      "metadata": {
        "id": "ZwZqQ4e99GTH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ptb\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "k1FDg3Ft9HH-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの設定\n",
        "batch_size = 10\n",
        "wordvec_size = 100\n",
        "hidden_size = 100 # RNNの隠れ状態ベクトルの要素数\n",
        "time_size = 5 # Truncated BPTTの展開する時間サイズ\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "# 学習データの読み込み（データセットを小さくする）\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus) + 1)\n",
        "\n",
        "xs = corpus[:-1] # 入力\n",
        "ts = corpus[1:] # 出力（教師データ）\n",
        "data_size = len(xs)\n",
        "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))\n",
        "\n",
        "# 学習時に使用する変数\n",
        "max_iters = data_size // (batch_size * time_size)\n",
        "time_idx = 0\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "ppl_list = []\n",
        "\n",
        "# モデルの生成\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "\n",
        "# ①ミニバッチの各サンプルの読み込み開始位置を計算\n",
        "jump = (corpus_size - 1) // batch_size\n",
        "offsets = [i * jump for i in range(batch_size)]\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for iter in range(max_iters):\n",
        "        # ②ミニバッチの取得\n",
        "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
        "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
        "        for t in range(time_size):\n",
        "            for i, offset in enumerate(offsets):\n",
        "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
        "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
        "            time_idx += 1\n",
        "\n",
        "        # 勾配を求め、パラメータを更新\n",
        "        loss = model.forward(batch_x, batch_t)\n",
        "        model.backward()\n",
        "        optimizer.update(model.params, model.grads)\n",
        "        total_loss += loss\n",
        "        loss_count += 1\n",
        "    \n",
        "    # ③エポックごとにパープレキシティの評価\n",
        "    ppl = np.exp(total_loss / loss_count)\n",
        "    print('| epoch %d | perplexity %.2f' % (epoch + 1, ppl))\n",
        "    ppl_list.append(float(ppl))\n",
        "    total_loss, loss_count = 0, 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkJZSnfa9Tjc",
        "outputId": "d6df0ba2-9ed4-4457-96a2-5e02695d33b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n",
            "corpus size: 1000, vocabulary size: 418\n",
            "| epoch 1 | perplexity 392.22\n",
            "| epoch 2 | perplexity 269.36\n",
            "| epoch 3 | perplexity 227.48\n",
            "| epoch 4 | perplexity 216.70\n",
            "| epoch 5 | perplexity 207.04\n",
            "| epoch 6 | perplexity 202.92\n",
            "| epoch 7 | perplexity 199.85\n",
            "| epoch 8 | perplexity 197.37\n",
            "| epoch 9 | perplexity 191.51\n",
            "| epoch 10 | perplexity 193.10\n",
            "| epoch 11 | perplexity 189.27\n",
            "| epoch 12 | perplexity 192.82\n",
            "| epoch 13 | perplexity 191.10\n",
            "| epoch 14 | perplexity 190.18\n",
            "| epoch 15 | perplexity 189.94\n",
            "| epoch 16 | perplexity 186.34\n",
            "| epoch 17 | perplexity 184.27\n",
            "| epoch 18 | perplexity 181.55\n",
            "| epoch 19 | perplexity 182.50\n",
            "| epoch 20 | perplexity 184.48\n",
            "| epoch 21 | perplexity 182.25\n",
            "| epoch 22 | perplexity 177.52\n",
            "| epoch 23 | perplexity 176.67\n",
            "| epoch 24 | perplexity 176.90\n",
            "| epoch 25 | perplexity 173.71\n",
            "| epoch 26 | perplexity 174.20\n",
            "| epoch 27 | perplexity 170.66\n",
            "| epoch 28 | perplexity 168.75\n",
            "| epoch 29 | perplexity 164.35\n",
            "| epoch 30 | perplexity 159.36\n",
            "| epoch 31 | perplexity 162.13\n",
            "| epoch 32 | perplexity 154.29\n",
            "| epoch 33 | perplexity 153.48\n",
            "| epoch 34 | perplexity 147.68\n",
            "| epoch 35 | perplexity 146.99\n",
            "| epoch 36 | perplexity 140.27\n",
            "| epoch 37 | perplexity 137.05\n",
            "| epoch 38 | perplexity 133.49\n",
            "| epoch 39 | perplexity 129.03\n",
            "| epoch 40 | perplexity 123.12\n",
            "| epoch 41 | perplexity 124.18\n",
            "| epoch 42 | perplexity 116.88\n",
            "| epoch 43 | perplexity 111.35\n",
            "| epoch 44 | perplexity 106.42\n",
            "| epoch 45 | perplexity 103.31\n",
            "| epoch 46 | perplexity 102.90\n",
            "| epoch 47 | perplexity 95.81\n",
            "| epoch 48 | perplexity 90.88\n",
            "| epoch 49 | perplexity 85.83\n",
            "| epoch 50 | perplexity 83.21\n",
            "| epoch 51 | perplexity 78.44\n",
            "| epoch 52 | perplexity 74.89\n",
            "| epoch 53 | perplexity 70.51\n",
            "| epoch 54 | perplexity 67.79\n",
            "| epoch 55 | perplexity 65.99\n",
            "| epoch 56 | perplexity 61.47\n",
            "| epoch 57 | perplexity 59.59\n",
            "| epoch 58 | perplexity 55.11\n",
            "| epoch 59 | perplexity 52.35\n",
            "| epoch 60 | perplexity 49.67\n",
            "| epoch 61 | perplexity 48.26\n",
            "| epoch 62 | perplexity 44.53\n",
            "| epoch 63 | perplexity 41.39\n",
            "| epoch 64 | perplexity 39.05\n",
            "| epoch 65 | perplexity 37.84\n",
            "| epoch 66 | perplexity 36.35\n",
            "| epoch 67 | perplexity 34.60\n",
            "| epoch 68 | perplexity 31.06\n",
            "| epoch 69 | perplexity 30.68\n",
            "| epoch 70 | perplexity 28.65\n",
            "| epoch 71 | perplexity 26.93\n",
            "| epoch 72 | perplexity 25.80\n",
            "| epoch 73 | perplexity 23.46\n",
            "| epoch 74 | perplexity 22.73\n",
            "| epoch 75 | perplexity 22.06\n",
            "| epoch 76 | perplexity 19.87\n",
            "| epoch 77 | perplexity 18.89\n",
            "| epoch 78 | perplexity 17.67\n",
            "| epoch 79 | perplexity 16.94\n",
            "| epoch 80 | perplexity 15.79\n",
            "| epoch 81 | perplexity 15.37\n",
            "| epoch 82 | perplexity 14.84\n",
            "| epoch 83 | perplexity 14.45\n",
            "| epoch 84 | perplexity 13.81\n",
            "| epoch 85 | perplexity 12.72\n",
            "| epoch 86 | perplexity 12.36\n",
            "| epoch 87 | perplexity 10.97\n",
            "| epoch 88 | perplexity 10.82\n",
            "| epoch 89 | perplexity 10.30\n",
            "| epoch 90 | perplexity 9.79\n",
            "| epoch 91 | perplexity 9.45\n",
            "| epoch 92 | perplexity 8.77\n",
            "| epoch 93 | perplexity 8.55\n",
            "| epoch 94 | perplexity 9.04\n",
            "| epoch 95 | perplexity 8.94\n",
            "| epoch 96 | perplexity 7.57\n",
            "| epoch 97 | perplexity 7.27\n",
            "| epoch 98 | perplexity 6.92\n",
            "| epoch 99 | perplexity 6.46\n",
            "| epoch 100 | perplexity 6.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNLMのTrainerクラス"
      ],
      "metadata": {
        "id": "7G4_Q3-1A92c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import trainer"
      ],
      "metadata": {
        "id": "tkHA3aE2BqJZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメータの設定\n",
        "batch_size = 10\n",
        "wordvec_size = 100\n",
        "hidden_size = 100  # RNNの隠れ状態ベクトルの要素数\n",
        "time_size = 5  # RNNを展開するサイズ\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "# 学習データの読み込み\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000  # テスト用にデータセットを小さくする\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus) + 1)\n",
        "xs = corpus[:-1]  # 入力\n",
        "ts = corpus[1:]  # 出力（教師ラベル）\n",
        "\n",
        "# モデルの生成\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "trainer = trainer.RnnlmTrainer(model, optimizer)\n",
        "\n",
        "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
        "trainer.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bmHDIi24BZwr",
        "outputId": "652d719a-c012-4674-c532-305e7c2f76d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch 1 |  iter 1 / 19 | time 0[s] | perplexity 417.20\n",
            "| epoch 2 |  iter 1 / 19 | time 0[s] | perplexity 351.95\n",
            "| epoch 3 |  iter 1 / 19 | time 0[s] | perplexity 249.46\n",
            "| epoch 4 |  iter 1 / 19 | time 0[s] | perplexity 217.88\n",
            "| epoch 5 |  iter 1 / 19 | time 0[s] | perplexity 209.09\n",
            "| epoch 6 |  iter 1 / 19 | time 0[s] | perplexity 207.21\n",
            "| epoch 7 |  iter 1 / 19 | time 0[s] | perplexity 200.75\n",
            "| epoch 8 |  iter 1 / 19 | time 0[s] | perplexity 200.51\n",
            "| epoch 9 |  iter 1 / 19 | time 1[s] | perplexity 194.51\n",
            "| epoch 10 |  iter 1 / 19 | time 1[s] | perplexity 190.54\n",
            "| epoch 11 |  iter 1 / 19 | time 1[s] | perplexity 192.68\n",
            "| epoch 12 |  iter 1 / 19 | time 1[s] | perplexity 190.13\n",
            "| epoch 13 |  iter 1 / 19 | time 1[s] | perplexity 193.30\n",
            "| epoch 14 |  iter 1 / 19 | time 1[s] | perplexity 187.02\n",
            "| epoch 15 |  iter 1 / 19 | time 1[s] | perplexity 187.16\n",
            "| epoch 16 |  iter 1 / 19 | time 1[s] | perplexity 191.56\n",
            "| epoch 17 |  iter 1 / 19 | time 1[s] | perplexity 189.68\n",
            "| epoch 18 |  iter 1 / 19 | time 1[s] | perplexity 185.21\n",
            "| epoch 19 |  iter 1 / 19 | time 1[s] | perplexity 181.17\n",
            "| epoch 20 |  iter 1 / 19 | time 2[s] | perplexity 182.19\n",
            "| epoch 21 |  iter 1 / 19 | time 2[s] | perplexity 180.16\n",
            "| epoch 22 |  iter 1 / 19 | time 2[s] | perplexity 179.07\n",
            "| epoch 23 |  iter 1 / 19 | time 2[s] | perplexity 180.43\n",
            "| epoch 24 |  iter 1 / 19 | time 2[s] | perplexity 177.86\n",
            "| epoch 25 |  iter 1 / 19 | time 2[s] | perplexity 172.31\n",
            "| epoch 26 |  iter 1 / 19 | time 2[s] | perplexity 175.22\n",
            "| epoch 27 |  iter 1 / 19 | time 2[s] | perplexity 172.15\n",
            "| epoch 28 |  iter 1 / 19 | time 2[s] | perplexity 171.92\n",
            "| epoch 29 |  iter 1 / 19 | time 2[s] | perplexity 166.83\n",
            "| epoch 30 |  iter 1 / 19 | time 3[s] | perplexity 165.84\n",
            "| epoch 31 |  iter 1 / 19 | time 3[s] | perplexity 164.21\n",
            "| epoch 32 |  iter 1 / 19 | time 3[s] | perplexity 158.45\n",
            "| epoch 33 |  iter 1 / 19 | time 3[s] | perplexity 158.04\n",
            "| epoch 34 |  iter 1 / 19 | time 3[s] | perplexity 159.85\n",
            "| epoch 35 |  iter 1 / 19 | time 3[s] | perplexity 154.10\n",
            "| epoch 36 |  iter 1 / 19 | time 3[s] | perplexity 150.78\n",
            "| epoch 37 |  iter 1 / 19 | time 3[s] | perplexity 149.38\n",
            "| epoch 38 |  iter 1 / 19 | time 3[s] | perplexity 142.62\n",
            "| epoch 39 |  iter 1 / 19 | time 3[s] | perplexity 138.31\n",
            "| epoch 40 |  iter 1 / 19 | time 4[s] | perplexity 133.63\n",
            "| epoch 41 |  iter 1 / 19 | time 4[s] | perplexity 129.83\n",
            "| epoch 42 |  iter 1 / 19 | time 4[s] | perplexity 127.87\n",
            "| epoch 43 |  iter 1 / 19 | time 4[s] | perplexity 122.14\n",
            "| epoch 44 |  iter 1 / 19 | time 4[s] | perplexity 119.41\n",
            "| epoch 45 |  iter 1 / 19 | time 4[s] | perplexity 110.31\n",
            "| epoch 46 |  iter 1 / 19 | time 4[s] | perplexity 106.94\n",
            "| epoch 47 |  iter 1 / 19 | time 4[s] | perplexity 106.53\n",
            "| epoch 48 |  iter 1 / 19 | time 4[s] | perplexity 101.23\n",
            "| epoch 49 |  iter 1 / 19 | time 4[s] | perplexity 97.12\n",
            "| epoch 50 |  iter 1 / 19 | time 4[s] | perplexity 91.50\n",
            "| epoch 51 |  iter 1 / 19 | time 5[s] | perplexity 88.78\n",
            "| epoch 52 |  iter 1 / 19 | time 5[s] | perplexity 82.70\n",
            "| epoch 53 |  iter 1 / 19 | time 5[s] | perplexity 80.70\n",
            "| epoch 54 |  iter 1 / 19 | time 5[s] | perplexity 76.57\n",
            "| epoch 55 |  iter 1 / 19 | time 5[s] | perplexity 72.08\n",
            "| epoch 56 |  iter 1 / 19 | time 5[s] | perplexity 68.58\n",
            "| epoch 57 |  iter 1 / 19 | time 5[s] | perplexity 67.86\n",
            "| epoch 58 |  iter 1 / 19 | time 5[s] | perplexity 62.45\n",
            "| epoch 59 |  iter 1 / 19 | time 5[s] | perplexity 59.88\n",
            "| epoch 60 |  iter 1 / 19 | time 5[s] | perplexity 55.74\n",
            "| epoch 61 |  iter 1 / 19 | time 6[s] | perplexity 52.34\n",
            "| epoch 62 |  iter 1 / 19 | time 6[s] | perplexity 49.50\n",
            "| epoch 63 |  iter 1 / 19 | time 6[s] | perplexity 48.22\n",
            "| epoch 64 |  iter 1 / 19 | time 6[s] | perplexity 44.92\n",
            "| epoch 65 |  iter 1 / 19 | time 6[s] | perplexity 40.85\n",
            "| epoch 66 |  iter 1 / 19 | time 6[s] | perplexity 39.69\n",
            "| epoch 67 |  iter 1 / 19 | time 6[s] | perplexity 37.50\n",
            "| epoch 68 |  iter 1 / 19 | time 6[s] | perplexity 35.90\n",
            "| epoch 69 |  iter 1 / 19 | time 6[s] | perplexity 35.34\n",
            "| epoch 70 |  iter 1 / 19 | time 6[s] | perplexity 31.17\n",
            "| epoch 71 |  iter 1 / 19 | time 6[s] | perplexity 30.63\n",
            "| epoch 72 |  iter 1 / 19 | time 7[s] | perplexity 28.57\n",
            "| epoch 73 |  iter 1 / 19 | time 7[s] | perplexity 26.65\n",
            "| epoch 74 |  iter 1 / 19 | time 7[s] | perplexity 25.79\n",
            "| epoch 75 |  iter 1 / 19 | time 7[s] | perplexity 24.47\n",
            "| epoch 76 |  iter 1 / 19 | time 7[s] | perplexity 22.32\n",
            "| epoch 77 |  iter 1 / 19 | time 7[s] | perplexity 20.90\n",
            "| epoch 78 |  iter 1 / 19 | time 7[s] | perplexity 20.63\n",
            "| epoch 79 |  iter 1 / 19 | time 7[s] | perplexity 19.51\n",
            "| epoch 80 |  iter 1 / 19 | time 7[s] | perplexity 17.79\n",
            "| epoch 81 |  iter 1 / 19 | time 7[s] | perplexity 16.78\n",
            "| epoch 82 |  iter 1 / 19 | time 8[s] | perplexity 16.20\n",
            "| epoch 83 |  iter 1 / 19 | time 8[s] | perplexity 15.71\n",
            "| epoch 84 |  iter 1 / 19 | time 8[s] | perplexity 14.68\n",
            "| epoch 85 |  iter 1 / 19 | time 8[s] | perplexity 13.39\n",
            "| epoch 86 |  iter 1 / 19 | time 8[s] | perplexity 13.20\n",
            "| epoch 87 |  iter 1 / 19 | time 8[s] | perplexity 13.14\n",
            "| epoch 88 |  iter 1 / 19 | time 8[s] | perplexity 11.65\n",
            "| epoch 89 |  iter 1 / 19 | time 8[s] | perplexity 11.39\n",
            "| epoch 90 |  iter 1 / 19 | time 8[s] | perplexity 10.17\n",
            "| epoch 91 |  iter 1 / 19 | time 8[s] | perplexity 10.06\n",
            "| epoch 92 |  iter 1 / 19 | time 9[s] | perplexity 9.45\n",
            "| epoch 93 |  iter 1 / 19 | time 9[s] | perplexity 8.90\n",
            "| epoch 94 |  iter 1 / 19 | time 9[s] | perplexity 8.52\n",
            "| epoch 95 |  iter 1 / 19 | time 9[s] | perplexity 8.22\n",
            "| epoch 96 |  iter 1 / 19 | time 9[s] | perplexity 8.15\n",
            "| epoch 97 |  iter 1 / 19 | time 9[s] | perplexity 7.61\n",
            "| epoch 98 |  iter 1 / 19 | time 9[s] | perplexity 7.26\n",
            "| epoch 99 |  iter 1 / 19 | time 9[s] | perplexity 6.52\n",
            "| epoch 100 |  iter 1 / 19 | time 9[s] | perplexity 6.05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}